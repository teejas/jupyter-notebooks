{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "n3KmbMF-3dOl"
   },
   "source": [
    "## Setup\n",
    "First, let's make sure we're in the correct working directory and have all the necessary packages imported.\n",
    "We'll also read in the dataset--It's been cleaned beforehand on my local machine; a simple process to get it into a csv rather than the SQLLite db I had downloaded.\n",
    "Finally, we'll set a flag to indicate which vectorizer we are using in the interest of testing both and comparing (A/B testing).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 2320,
     "status": "ok",
     "timestamp": 1593566523398,
     "user": {
      "displayName": "Tejas Siripurapu",
      "photoUrl": "https://lh5.googleusercontent.com/-zGBqxY2QvYA/AAAAAAAAAAI/AAAAAAAAChw/Vo7W1nfwMBU/s64/photo.jpg",
      "userId": "12304133152416668209"
     },
     "user_tz": 420
    },
    "id": "ohv0Zrl62YTx",
    "outputId": "b54bf737-bb1b-45e6-b63e-19bfade0110e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Errno 2] No such file or directory: 'drive/My Drive/Colab Notebooks'\n",
      "/Users/tejassiripurapu/Notebooks\n",
      "/Users/tejassiripurapu/Notebooks\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: sklearn in /Users/tejassiripurapu/Library/Python/3.7/lib/python/site-packages (0.0)\n",
      "Requirement already satisfied: pandas in /Users/tejassiripurapu/Library/Python/3.7/lib/python/site-packages (1.0.5)\n",
      "Requirement already satisfied: rake_nltk in /Users/tejassiripurapu/Library/Python/3.7/lib/python/site-packages (1.0.4)\n",
      "Requirement already satisfied: scikit-learn in /Users/tejassiripurapu/Library/Python/3.7/lib/python/site-packages (from sklearn) (0.23.1)\n",
      "Requirement already satisfied: python-dateutil>=2.6.1 in /Users/tejassiripurapu/Library/Python/3.7/lib/python/site-packages (from pandas) (2.8.1)\n",
      "Requirement already satisfied: pytz>=2017.2 in /Users/tejassiripurapu/Library/Python/3.7/lib/python/site-packages (from pandas) (2020.1)\n",
      "Requirement already satisfied: numpy>=1.13.3 in /Users/tejassiripurapu/Library/Python/3.7/lib/python/site-packages (from pandas) (1.18.5)\n",
      "Requirement already satisfied: nltk in /Users/tejassiripurapu/Library/Python/3.7/lib/python/site-packages (from rake_nltk) (3.5)\n",
      "Requirement already satisfied: scipy>=0.19.1 in /Users/tejassiripurapu/Library/Python/3.7/lib/python/site-packages (from scikit-learn->sklearn) (1.4.1)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /Users/tejassiripurapu/Library/Python/3.7/lib/python/site-packages (from scikit-learn->sklearn) (2.1.0)\n",
      "Requirement already satisfied: joblib>=0.11 in /Users/tejassiripurapu/Library/Python/3.7/lib/python/site-packages (from scikit-learn->sklearn) (0.15.1)\n",
      "Requirement already satisfied: six>=1.5 in /Applications/Xcode.app/Contents/Developer/Library/Frameworks/Python3.framework/Versions/3.7/lib/python3.7/site-packages (from python-dateutil>=2.6.1->pandas) (1.12.0)\n",
      "Requirement already satisfied: click in /Users/tejassiripurapu/Library/Python/3.7/lib/python/site-packages (from nltk->rake_nltk) (7.1.2)\n",
      "Requirement already satisfied: tqdm in /Users/tejassiripurapu/Library/Python/3.7/lib/python/site-packages (from nltk->rake_nltk) (4.47.0)\n",
      "Requirement already satisfied: regex in /Users/tejassiripurapu/Library/Python/3.7/lib/python/site-packages (from nltk->rake_nltk) (2020.6.8)\n"
     ]
    }
   ],
   "source": [
    "%cd \"drive/My Drive/Colab Notebooks\"\n",
    "!pwd\n",
    "!pip3 install sklearn pandas rake_nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 3978,
     "status": "ok",
     "timestamp": 1593566525158,
     "user": {
      "displayName": "Tejas Siripurapu",
      "photoUrl": "https://lh5.googleusercontent.com/-zGBqxY2QvYA/AAAAAAAAAAI/AAAAAAAAChw/Vo7W1nfwMBU/s64/photo.jpg",
      "userId": "12304133152416668209"
     },
     "user_tz": 420
    },
    "id": "NMGuGQ6h2wrk"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from rake_nltk import Rake\n",
    "from sklearn.metrics.pairwise import cosine_similarity, euclidean_distances\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 153
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 6016,
     "status": "ok",
     "timestamp": 1593566527222,
     "user": {
      "displayName": "Tejas Siripurapu",
      "photoUrl": "https://lh5.googleusercontent.com/-zGBqxY2QvYA/AAAAAAAAAAI/AAAAAAAAChw/Vo7W1nfwMBU/s64/photo.jpg",
      "userId": "12304133152416668209"
     },
     "user_tz": 420
    },
    "id": "SYtqB-4y3Rey",
    "outputId": "b6bed765-e69c-4919-c1bc-bc3ffc1c4e37"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             artist                                       album       genre  \\\n",
      "0       David Byrne  “…The Best Live Show of All Time” — NME EP        Rock   \n",
      "1         DJ Healer           Lost Lovesongs / Lostsongs Vol. 2  Electronic   \n",
      "2       Jorge Velez                                 Roman Birds  Electronic   \n",
      "3           Chandra                          Transportation EPs        Rock   \n",
      "4  The Chainsmokers                                    Sick Boy  Electronic   \n",
      "\n",
      "   score             author                                             review  \n",
      "0    5.5          Andy Beta  Viva Brother, Terris, Mansun, the Twang, Joe L...  \n",
      "1    6.2        Chal Ravens  The Prince of Denmark—that is, the proper prin...  \n",
      "2    7.9   Philip Sherburne  Jorge Velez has long been prolific, but that’s...  \n",
      "3    7.8          Andy Beta  When the Avalanches returned in 2016 after an ...  \n",
      "4    3.1  Larry Fitzmaurice  We’re going to be stuck with the Chainsmokers ...  \n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(\"data/pitchfork_reviews_cleaned.csv\")\n",
    "print(df.head())\n",
    "\n",
    "tfidf = True # if True: use TfidfVectorizer, else: CountVectorizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "_iAeGdRf3vkD"
   },
   "source": [
    "## A Little Preprocessing\n",
    "Now that our data is loaded into a dataframe, let's separate out the written review and use the album title as the index.\n",
    "\n",
    "NOTE: The set we're working with may be too big to handle atm (session is crashing when trying to vectorize). Randomly sample 8000 reviews to begin with"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 187
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 6009,
     "status": "ok",
     "timestamp": 1593566527229,
     "user": {
      "displayName": "Tejas Siripurapu",
      "photoUrl": "https://lh5.googleusercontent.com/-zGBqxY2QvYA/AAAAAAAAAAI/AAAAAAAAChw/Vo7W1nfwMBU/s64/photo.jpg",
      "userId": "12304133152416668209"
     },
     "user_tz": 420
    },
    "id": "wgxjupfh9Z_7",
    "outputId": "8c757796-1c2e-4d16-b51b-e4a5f38cd537"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             artist                                       album  \\\n",
      "0       David Byrne  “…The Best Live Show of All Time” — NME EP   \n",
      "1         DJ Healer           Lost Lovesongs / Lostsongs Vol. 2   \n",
      "2       Jorge Velez                                 Roman Birds   \n",
      "3           Chandra                          Transportation EPs   \n",
      "4  The Chainsmokers                                    Sick Boy   \n",
      "\n",
      "                                              review  \n",
      "0  Viva Brother, Terris, Mansun, the Twang, Joe L...  \n",
      "1  The Prince of Denmark—that is, the proper prin...  \n",
      "2  Jorge Velez has long been prolific, but that’s...  \n",
      "3  When the Avalanches returned in 2016 after an ...  \n",
      "4  We’re going to be stuck with the Chainsmokers ...  \n",
      "20873\n",
      "20867\n"
     ]
    }
   ],
   "source": [
    "working_df = df[['artist', 'album', 'review']].copy()\n",
    "# working_df.set_index('album', inplace=True)\n",
    "print(working_df.head())\n",
    "print(len(working_df))\n",
    "working_df.dropna(inplace=True, how='any')\n",
    "print(len(working_df)) # How many na rows were there? 5 (which ones?)\n",
    "sample_df = working_df.sample(8000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "tO_fWaG-818E"
   },
   "source": [
    "## Keyword Extraction\n",
    "\n",
    "Use the nltk Rake function (from rake-nltk Python package) to extract important keywords from the reviews. This improves the vectorization by removing punctuation and allows for larger batch size by decreasing size of corpus and individual docs (reviews). \n",
    "\n",
    "Furthermore, as a new Rake object is instantiated for every row in the dataframe, I've added the artist name as a stopword when extracting keywords for any given review of an artist. This is because the artist name is likely used frequently in a review of their music, so our similarity scores (and therefore recommendations) will be skewed towards albums by that artist. We want more variety to the recommendation, a user has likely already heard of other albums by the same artist--or can simply Google it. \n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 48985,
     "status": "ok",
     "timestamp": 1593566570217,
     "user": {
      "displayName": "Tejas Siripurapu",
      "photoUrl": "https://lh5.googleusercontent.com/-zGBqxY2QvYA/AAAAAAAAAAI/AAAAAAAAChw/Vo7W1nfwMBU/s64/photo.jpg",
      "userId": "12304133152416668209"
     },
     "user_tz": 420
    },
    "id": "6ySIqwvF80ZJ"
   },
   "outputs": [],
   "source": [
    "artists = sample_df['artist']\n",
    "\n",
    "sample_df['keywords'] = \"\"\n",
    "\n",
    "for idx, row in sample_df.iterrows():\n",
    "  r = Rake(stopwords=artists[idx])\n",
    "  r.extract_keywords_from_text(row['review'])\n",
    "  keywords = list(r.get_word_degrees().keys())\n",
    "  row['keywords'] = \" \".join(keywords)\n",
    "\n",
    "corpus = sample_df['keywords']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "0wa9wGZW6cCk"
   },
   "source": [
    "## Vectorization\n",
    "The working dataframe is set up containing album titles (as index) and the full written review. We're going to vectorize that review column using Tfidf. This will give us a vector of word frequencies across the whole corpus. Think of this as mapping every review onto an n-dimensional space, where n is the number of distinct words in the corpus. Then we can measure similarity between the vectors using cosine similarity.\n",
    "Admittedly, Tfidf is a little different as it measures frequency relative to how often that word appears in different documents, but this is a good way to conceptualize.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 58773,
     "status": "ok",
     "timestamp": 1593566580152,
     "user": {
      "displayName": "Tejas Siripurapu",
      "photoUrl": "https://lh5.googleusercontent.com/-zGBqxY2QvYA/AAAAAAAAAAI/AAAAAAAAChw/Vo7W1nfwMBU/s64/photo.jpg",
      "userId": "12304133152416668209"
     },
     "user_tz": 420
    },
    "id": "01Cy9JrU7ECC",
    "outputId": "9adf9236-7ce7-4158-94b4-aae4275dde4b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "89524\n"
     ]
    }
   ],
   "source": [
    "if tfidf:\n",
    "  tv = TfidfVectorizer()\n",
    "  tv_counts = tv.fit_transform(corpus)\n",
    "  # tv_counts = tv.transform(df['review'])\n",
    "  tv_counts = tv_counts.toarray()\n",
    "  print(len(tv_counts[0])) # How many words are being counted?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 485,
     "status": "ok",
     "timestamp": 1593566626692,
     "user": {
      "displayName": "Tejas Siripurapu",
      "photoUrl": "https://lh5.googleusercontent.com/-zGBqxY2QvYA/AAAAAAAAAAI/AAAAAAAAChw/Vo7W1nfwMBU/s64/photo.jpg",
      "userId": "12304133152416668209"
     },
     "user_tz": 420
    },
    "id": "LokVVZfJHPOx"
   },
   "outputs": [],
   "source": [
    "if not tfidf:\n",
    "    cv = CountVectorizer()\n",
    "    cv_counts = cv.fit_transform(corpus)\n",
    "    cv_counts = cv_counts.toarray()\n",
    "    print(len(cv_counts[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 170
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 637,
     "status": "ok",
     "timestamp": 1593566632759,
     "user": {
      "displayName": "Tejas Siripurapu",
      "photoUrl": "https://lh5.googleusercontent.com/-zGBqxY2QvYA/AAAAAAAAAAI/AAAAAAAAChw/Vo7W1nfwMBU/s64/photo.jpg",
      "userId": "12304133152416668209"
     },
     "user_tz": 420
    },
    "id": "aSuQmDZG73U9",
    "outputId": "5247511e-0f16-49b4-a8f1-e0da299292a6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                 word0  word1  word2  word3  word4  word5  \\\n",
      "album                                                                       \n",
      "Pimps Don't Pay Taxes              0.0    0.0    0.0    0.0    0.0    0.0   \n",
      "Exmilitary                         0.0    0.0    0.0    0.0    0.0    0.0   \n",
      "Like Someone In Love EP            0.0    0.0    0.0    0.0    0.0    0.0   \n",
      "Expressions (2012 A.U.)            0.0    0.0    0.0    0.0    0.0    0.0   \n",
      "Songs from the Hermetic Theatre    0.0    0.0    0.0    0.0    0.0    0.0   \n",
      "\n",
      "                                 word6  word7  word8  word9  ...  word89514  \\\n",
      "album                                                        ...              \n",
      "Pimps Don't Pay Taxes              0.0    0.0    0.0    0.0  ...        0.0   \n",
      "Exmilitary                         0.0    0.0    0.0    0.0  ...        0.0   \n",
      "Like Someone In Love EP            0.0    0.0    0.0    0.0  ...        0.0   \n",
      "Expressions (2012 A.U.)            0.0    0.0    0.0    0.0  ...        0.0   \n",
      "Songs from the Hermetic Theatre    0.0    0.0    0.0    0.0  ...        0.0   \n",
      "\n",
      "                                 word89515  word89516  word89517  word89518  \\\n",
      "album                                                                         \n",
      "Pimps Don't Pay Taxes                  0.0        0.0        0.0        0.0   \n",
      "Exmilitary                             0.0        0.0        0.0        0.0   \n",
      "Like Someone In Love EP                0.0        0.0        0.0        0.0   \n",
      "Expressions (2012 A.U.)                0.0        0.0        0.0        0.0   \n",
      "Songs from the Hermetic Theatre        0.0        0.0        0.0        0.0   \n",
      "\n",
      "                                 word89519  word89520  word89521  word89522  \\\n",
      "album                                                                         \n",
      "Pimps Don't Pay Taxes                  0.0        0.0        0.0        0.0   \n",
      "Exmilitary                             0.0        0.0        0.0        0.0   \n",
      "Like Someone In Love EP                0.0        0.0        0.0        0.0   \n",
      "Expressions (2012 A.U.)                0.0        0.0        0.0        0.0   \n",
      "Songs from the Hermetic Theatre        0.0        0.0        0.0        0.0   \n",
      "\n",
      "                                 word89523  \n",
      "album                                       \n",
      "Pimps Don't Pay Taxes                  0.0  \n",
      "Exmilitary                             0.0  \n",
      "Like Someone In Love EP                0.0  \n",
      "Expressions (2012 A.U.)                0.0  \n",
      "Songs from the Hermetic Theatre        0.0  \n",
      "\n",
      "[5 rows x 89524 columns]\n"
     ]
    }
   ],
   "source": [
    "labels = []\n",
    "albums = sample_df['album']\n",
    "for i in range(len(tv_counts[0])):\n",
    "  labels.append(\"word\" + str(i))\n",
    "counts_df = pd.DataFrame(tv_counts, columns=labels, index=albums)\n",
    "print(counts_df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "vFAo5IRB_PRz"
   },
   "source": [
    "## (Cosine) Similarity \n",
    "Now we have a dataframe containing the word frequencies and we can compare each album using cosine similarity. Doing this in a pairwise manner (across every row in the dataframe) allows us to measure the similarity between two albums based on their review."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 102
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 181173,
     "status": "ok",
     "timestamp": 1593566817550,
     "user": {
      "displayName": "Tejas Siripurapu",
      "photoUrl": "https://lh5.googleusercontent.com/-zGBqxY2QvYA/AAAAAAAAAAI/AAAAAAAAChw/Vo7W1nfwMBU/s64/photo.jpg",
      "userId": "12304133152416668209"
     },
     "user_tz": 420
    },
    "id": "Yidyf09T_o9G",
    "outputId": "9344b493-8ed3-4a6a-f8c3-9c890fefb50c"
   },
   "outputs": [],
   "source": [
    "similarity = cosine_similarity(counts_df)\n",
    "print(similarity[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "pUcJ116d-AyD"
   },
   "source": [
    "God bless, everything ran and nothing has crashed yet (hopefully). Now let's make sense of the similarity matrix. Each album gets a row in the matrix (i.e. album[0] has a corresponding vector at similarity[0]).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "PVj-q6JSAu3X"
   },
   "source": [
    "## Recommendation and User Testing\n",
    "Every value in the album vector represents how similar that album is with another. So for album[i], there is a corresponding album vector such that the value at index j in that vector is showing how similar album[i] is with album[j]. If i == j we should see a value of 1, meaning that the two albums are exactly alike (as they should be, it's the same album).\n",
    "\n",
    "So to find recommendations for a given album, sort the corresponding similarity vector (while maintaining the index). Using the index of the highest value which isn't 1 will reference the album most similar to the given album based on the written Pitchfork review.\n",
    "\n",
    "The process to recommend is as follows: Given an input album title -> get review corresponding to album, vectorize using Tfidf, measure similarity against sample, return top 5 (or 10?) most similar albums."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 950,
     "status": "ok",
     "timestamp": 1593567435307,
     "user": {
      "displayName": "Tejas Siripurapu",
      "photoUrl": "https://lh5.googleusercontent.com/-zGBqxY2QvYA/AAAAAAAAAAI/AAAAAAAAChw/Vo7W1nfwMBU/s64/photo.jpg",
      "userId": "12304133152416668209"
     },
     "user_tz": 420
    },
    "id": "RGymzAPTHqLn"
   },
   "outputs": [],
   "source": [
    "working_df.set_index('album', inplace=True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 7294,
     "status": "ok",
     "timestamp": 1593567442484,
     "user": {
      "displayName": "Tejas Siripurapu",
      "photoUrl": "https://lh5.googleusercontent.com/-zGBqxY2QvYA/AAAAAAAAAAI/AAAAAAAAChw/Vo7W1nfwMBU/s64/photo.jpg",
      "userId": "12304133152416668209"
     },
     "user_tz": 420
    },
    "id": "X4SQ1Ap6CiNo",
    "outputId": "6a18d4ec-d2e1-4426-9610-ae116f6ce43d"
   },
   "outputs": [],
   "source": [
    "search_album = \"My Beautiful Dark Twisted Fantasy\"\n",
    "review = working_df.loc[search_album]['review']\n",
    "\n",
    "vec = tv.transform([review]).toarray()\n",
    "print(len(vec[0]))\n",
    "search_sim = cosine_similarity(vec, counts_df)\n",
    "print(search_sim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 102
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 6331,
     "status": "ok",
     "timestamp": 1593567442485,
     "user": {
      "displayName": "Tejas Siripurapu",
      "photoUrl": "https://lh5.googleusercontent.com/-zGBqxY2QvYA/AAAAAAAAAAI/AAAAAAAAChw/Vo7W1nfwMBU/s64/photo.jpg",
      "userId": "12304133152416668209"
     },
     "user_tz": 420
    },
    "id": "W8my1ZZKXeNK",
    "outputId": "e7c736b7-8e43-48a8-f3a7-125148211171"
   },
   "outputs": [],
   "source": [
    "search_df = pd.DataFrame(search_sim[0])\n",
    "top_5 = search_df.nlargest(5, 0)\n",
    "# print(top_5.index)\n",
    "for idx in top_5.index:\n",
    "  # print(idx)\n",
    "  print(albums.iloc[idx])"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyPK2zUPKLSRP+urgCN77i2/",
   "collapsed_sections": [],
   "mount_file_id": "1jMYF8Q6Pc-WfcbgLn71nVgKWNGgga55j",
   "name": "pitchfork_review_rec.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
